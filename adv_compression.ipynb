{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.utils import data\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.processed_folder, self.test_file))\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_gzip(gzip_path, remove_finished=False):\n",
    "        print('Extracting {}'.format(gzip_path))\n",
    "        with open(gzip_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                gzip.GzipFile(gzip_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "        if remove_finished:\n",
    "            os.unlink(gzip_path)\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        makedir_exist_ok(self.raw_folder)\n",
    "        makedir_exist_ok(self.processed_folder)\n",
    "\n",
    "        # download files\n",
    "        for url in self.urls:\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.raw_folder, filename)\n",
    "            download_url(url, root=self.raw_folder, filename=filename, md5=None)\n",
    "            self.extract_gzip(gzip_path=file_path, remove_finished=True)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "# trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "# from torchvision.datasets.utils import download_url, makedir_exist_ok\n",
    "\n",
    "import errno\n",
    "def makedir_exist_ok(dirpath):\n",
    "    \"\"\"\n",
    "    Python2 support for os.makedirs(.., exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def download_url(url, root, filename, md5):\n",
    "    from six.moves import urllib\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    makedir_exist_ok(root)\n",
    "\n",
    "    # downloads file\n",
    "    if os.path.isfile(fpath) and check_integrity(fpath, md5):\n",
    "        print('Using downloaded and verified file: ' + fpath)\n",
    "    else:\n",
    "        try:\n",
    "            print('Downloading ' + url + ' to ' + fpath)\n",
    "            urllib.request.urlretrieve(\n",
    "                url, fpath,\n",
    "                reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "            )\n",
    "        except OSError:\n",
    "            if url[:5] == 'https':\n",
    "                url = url.replace('https:', 'http:')\n",
    "                print('Failed download. Trying https -> http instead.'\n",
    "                      ' Downloading ' + url + ' to ' + fpath)\n",
    "                urllib.request.urlretrieve(\n",
    "                    url, fpath,\n",
    "                    reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "                )\n",
    "def gen_bar_updater(pbar):\n",
    "    def bar_update(count, block_size, total_size):\n",
    "        if pbar.total is None and total_size:\n",
    "            pbar.total = total_size\n",
    "        progress_bytes = count * block_size\n",
    "        pbar.update(progress_bytes - pbar.n)\n",
    "\n",
    "    return bar_update\n",
    "def check_integrity(fpath, md5=None):\n",
    "    if md5 is None:\n",
    "        return True\n",
    "    if not os.path.isfile(fpath):\n",
    "        return False\n",
    "    md5o = hashlib.md5()\n",
    "    with open(fpath, 'rb') as f:\n",
    "        # read in 1MB chunks\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
    "            md5o.update(chunk)\n",
    "    md5c = md5o.hexdigest()\n",
    "    if md5c != md5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n",
    "    \n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "train_set = MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "### script file\n",
    "\n",
    "# Parameters for training on GPU \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# params = {'batch_size': 64,\n",
    "#          'shuffle': True,\n",
    "#          'num_workers': 6}\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                dataset=train_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print ('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print ('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Linear(128*4*4, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.classifer(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "    # returns activation values for a specific input x\n",
    "#     def eval_act_features(self, x):\n",
    "#         activations = []\n",
    "#         for idx in range(len(self.features)):\n",
    "#             features[idx]\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model.name()):\n",
    "    model.load_state_dict(torch.load(model.name()))\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # from __future__ import division\n",
    "    for epoch in range(iters):\n",
    "        # trainning\n",
    "        ave_loss = 0\n",
    "        for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "    #         x, target = Variable(x), Variable(target)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, target)\n",
    "            ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "                print ('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "                    epoch, batch_idx+1, ave_loss))\n",
    "        # testing\n",
    "        correct_cnt, ave_loss = 0.0, 0.0\n",
    "        total_cnt = 0.0\n",
    "        for batch_idx, (x, target) in enumerate(test_loader):\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "    #         x, target = Variable(x), Variable(target)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, target)\n",
    "            _, pred_label = torch.max(out.data, 1)\n",
    "            total_cnt += x.data.size()[0]\n",
    "            correct_cnt += (pred_label == target.data).sum()\n",
    "    #         print(type(total_cnt))\n",
    "    #         print(correct_cnt.shape)\n",
    "            # smooth average\n",
    "            ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "    #         correct_cnt = correct_cnt.to(dtype=torch.float)\n",
    "            if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "                acc = float(correct_cnt * 1.0) / float(total_cnt)\n",
    "                print ('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                    epoch, batch_idx+1, ave_loss, acc))\n",
    "\n",
    "    torch.save(model.state_dict(), model.name())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "\n",
    "# create foolbox model\n",
    "fmodel = foolbox.models.PyTorchModel(model.eval(), bounds=(0, 1), num_classes=10)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=10000,\n",
    "                shuffle=False)\n",
    "\n",
    "for batch_idx, (x, target) in enumerate(test_loader2):\n",
    "    x, target = x, target\n",
    "\n",
    "np_x = x.numpy()\n",
    "\n",
    "target_np = target.numpy()\n",
    "\n",
    "attack = foolbox.attacks.FGSM(fmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.8226302 -2.645529  12.079064   1.3903521 -4.1643486 -5.978353\n",
      " -8.055495   1.3216019  5.304184  -0.9277481]\n",
      "normal classification: 2\n",
      "[ 2.9095805  -3.889592    2.6850235   1.0576442  -0.6220811  -5.332099\n",
      " -6.671054    0.50232494  5.1210713   3.8660326 ]\n",
      "adv classification 8\n"
     ]
    }
   ],
   "source": [
    "image_idx = 400\n",
    "\n",
    "print(fmodel.predictions(np_x[image_idx]))\n",
    "\n",
    "print(\"normal classification:\", np.argmax(fmodel.predictions(np_x[image_idx])))\n",
    "\n",
    "adv = attack(np_x[image_idx], int(target[image_idx]),epsilons=[epsilon])\n",
    "\n",
    "print(fmodel.predictions(adv))\n",
    "print(\"adv classification\", np.argmax(fmodel.predictions(adv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Legitimate')\n",
    "plt.imshow(np.reshape(np_x[image_idx],[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Adverserial')\n",
    "plt.imshow(np.reshape(adv,[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Difference')\n",
    "diff = np.reshape(np_x[image_idx],[28,28]) - np.reshape(adv,[28,28])\n",
    "plt.imshow(diff/abs(diff).max() * 0.2 + 0.5, interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "# plt.show()\n",
    "plt.savefig('adv_diff.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research/rraju2/anaconda2/envs/torch3/lib/python3.5/site-packages/foolbox/attacks/base.py:148: UserWarning: GradientSignAttack did not find an adversarial, maybe the model or the criterion is not supported by this attack.\n",
      "  ' attack.'.format(self.name()))\n",
      "/research/rraju2/anaconda2/envs/torch3/lib/python3.5/site-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
      "  warnings.warn('Not running the attack because the original input'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ep: 0.01, classification rate: 0.998\n",
      "For ep: 0.01, classification rate: 0.998\n",
      "For ep: 0.02, classification rate: 0.997\n",
      "For ep: 0.02, classification rate: 0.993\n",
      "For ep: 0.03, classification rate: 0.992\n",
      "For ep: 0.03, classification rate: 0.983\n",
      "For ep: 0.03, classification rate: 0.981\n",
      "For ep: 0.04, classification rate: 0.975\n",
      "For ep: 0.04, classification rate: 0.967\n",
      "For ep: 0.04, classification rate: 0.962\n",
      "For ep: 0.05, classification rate: 0.960\n",
      "For ep: 0.05, classification rate: 0.953\n",
      "For ep: 0.06, classification rate: 0.939\n",
      "For ep: 0.06, classification rate: 0.934\n",
      "For ep: 0.06, classification rate: 0.928\n",
      "For ep: 0.07, classification rate: 0.922\n",
      "For ep: 0.07, classification rate: 0.912\n",
      "For ep: 0.08, classification rate: 0.898\n",
      "For ep: 0.08, classification rate: 0.887\n",
      "For ep: 0.08, classification rate: 0.875\n",
      "For ep: 0.09, classification rate: 0.859\n",
      "For ep: 0.09, classification rate: 0.845\n",
      "For ep: 0.10, classification rate: 0.835\n",
      "For ep: 0.10, classification rate: 0.823\n",
      "For ep: 0.10, classification rate: 0.809\n",
      "For ep: 0.11, classification rate: 0.787\n",
      "For ep: 0.11, classification rate: 0.771\n",
      "For ep: 0.11, classification rate: 0.755\n",
      "For ep: 0.12, classification rate: 0.736\n",
      "For ep: 0.12, classification rate: 0.717\n",
      "For ep: 0.13, classification rate: 0.700\n",
      "For ep: 0.13, classification rate: 0.683\n",
      "For ep: 0.13, classification rate: 0.663\n",
      "For ep: 0.14, classification rate: 0.644\n",
      "For ep: 0.14, classification rate: 0.623\n",
      "For ep: 0.15, classification rate: 0.605\n",
      "For ep: 0.15, classification rate: 0.590\n",
      "For ep: 0.15, classification rate: 0.566\n",
      "For ep: 0.16, classification rate: 0.561\n",
      "For ep: 0.16, classification rate: 0.549\n",
      "For ep: 0.17, classification rate: 0.536\n",
      "For ep: 0.17, classification rate: 0.515\n",
      "For ep: 0.17, classification rate: 0.500\n",
      "For ep: 0.18, classification rate: 0.483\n",
      "For ep: 0.18, classification rate: 0.461\n",
      "For ep: 0.18, classification rate: 0.447\n",
      "For ep: 0.19, classification rate: 0.432\n",
      "For ep: 0.19, classification rate: 0.423\n",
      "For ep: 0.20, classification rate: 0.406\n",
      "For ep: 0.20, classification rate: 0.389\n"
     ]
    }
   ],
   "source": [
    "trial_eps = np.linspace(0.01, 0.2)\n",
    "# it takes a long time to run this cell \n",
    "classification_rates = []\n",
    "\n",
    "for ep in trial_eps:\n",
    "    adv_errors = 0\n",
    "    for i in range(1000):\n",
    "        image = np_x[i]\n",
    "        label = target_np[i]\n",
    "    #     print('normal class:', np.argmax(fmodel.predictions(image)), label)\n",
    "        adv = attack(image, int(label), epsilons=np.linspace(0.,ep,10)[1:])\n",
    "        pred = np.argmax(fmodel.predictions(image))\n",
    "        if adv is not None:\n",
    "            adv_pred = np.argmax(fmodel.predictions(adv))\n",
    "            if pred != adv_pred:\n",
    "                adv_errors = adv_errors + 1\n",
    "    acc = (1-(adv_errors/1000))\n",
    "    classification_rates.append(acc)\n",
    "    print(\"For ep: {:.4f}, classification rate: {:.5f}\".format(\n",
    "                ep, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trial_eps, classification_rates, 'bo-')\n",
    "plt.title('Accuracy vs. Epsilon Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the compressed imgs and corresponding labels\n",
    "mat = scipy.io.loadmat('compr.mat')\n",
    "compr_imgs = mat['jpeg_compressed_imgs']\n",
    "compr_test_labels = mat['sub_test_labels']\n",
    "\n",
    "# Get desired shape\n",
    "compr_imgs = np.reshape(compr_imgs, (100, 28, 28)) # put batch first\n",
    "c_imgs = torch.Tensor(compr_imgs) \n",
    "\n",
    "# None is basically a placeholder for 1 if we were working RGB color imgs, this would be 3\n",
    "c_imgs_ex = c_imgs[:,None,:,:] # Batch size, channel_num, img height, img width\n",
    "c_imgs_ex = c_imgs_ex.cuda() # need to put onto GPU for input to be accepted by model\n",
    "\n",
    "logits = model(c_imgs_ex)\n",
    "_, preds = torch.max(logits, 1) # get the most likely class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds = preds.size(0) # number of predictions\n",
    "pred_array = preds.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on compressed images: 9.000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(num_preds):\n",
    "    if pred_array[i] == compr_test_labels[i]:\n",
    "        correct = correct + 1\n",
    "\n",
    "acc = (correct/num_preds) * 100\n",
    "\n",
    "print(\"Classification accuracy on compressed images: {:.3f}\".format(\n",
    "                acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
