{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.utils import data\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "# import codecs\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.processed_folder, self.test_file))\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_gzip(gzip_path, remove_finished=False):\n",
    "        print('Extracting {}'.format(gzip_path))\n",
    "        with open(gzip_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                gzip.GzipFile(gzip_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "        if remove_finished:\n",
    "            os.unlink(gzip_path)\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        makedir_exist_ok(self.raw_folder)\n",
    "        makedir_exist_ok(self.processed_folder)\n",
    "\n",
    "        # download files\n",
    "        for url in self.urls:\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.raw_folder, filename)\n",
    "            download_url(url, root=self.raw_folder, filename=filename, md5=None)\n",
    "            self.extract_gzip(gzip_path=file_path, remove_finished=True)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "# trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "# from torchvision.datasets.utils import download_url, makedir_exist_ok\n",
    "\n",
    "import errno\n",
    "def makedir_exist_ok(dirpath):\n",
    "    \"\"\"\n",
    "    Python2 support for os.makedirs(.., exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def download_url(url, root, filename, md5):\n",
    "    from six.moves import urllib\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    makedir_exist_ok(root)\n",
    "\n",
    "    # downloads file\n",
    "    if os.path.isfile(fpath) and check_integrity(fpath, md5):\n",
    "        print('Using downloaded and verified file: ' + fpath)\n",
    "    else:\n",
    "        try:\n",
    "            print('Downloading ' + url + ' to ' + fpath)\n",
    "            urllib.request.urlretrieve(\n",
    "                url, fpath,\n",
    "                reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "            )\n",
    "        except OSError:\n",
    "            if url[:5] == 'https':\n",
    "                url = url.replace('https:', 'http:')\n",
    "                print('Failed download. Trying https -> http instead.'\n",
    "                      ' Downloading ' + url + ' to ' + fpath)\n",
    "                urllib.request.urlretrieve(\n",
    "                    url, fpath,\n",
    "                    reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "                )\n",
    "def gen_bar_updater(pbar):\n",
    "    def bar_update(count, block_size, total_size):\n",
    "        if pbar.total is None and total_size:\n",
    "            pbar.total = total_size\n",
    "        progress_bytes = count * block_size\n",
    "        pbar.update(progress_bytes - pbar.n)\n",
    "\n",
    "    return bar_update\n",
    "def check_integrity(fpath, md5=None):\n",
    "    if md5 is None:\n",
    "        return True\n",
    "    if not os.path.isfile(fpath):\n",
    "        return False\n",
    "    md5o = hashlib.md5()\n",
    "    with open(fpath, 'rb') as f:\n",
    "        # read in 1MB chunks\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
    "            md5o.update(chunk)\n",
    "    md5c = md5o.hexdigest()\n",
    "    if md5c != md5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n",
    "    \n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "train_set = MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "### script file\n",
    "\n",
    "# Parameters for training on GPU \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# params = {'batch_size': 64,\n",
    "#          'shuffle': True,\n",
    "#          'num_workers': 6}\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                dataset=train_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print ('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print ('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Linear(128*4*4, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.classifer(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "    # returns activation values for a specific input x\n",
    "#     def eval_act_features(self, x):\n",
    "#         activations = []\n",
    "#         for idx in range(len(self.features)):\n",
    "#             features[idx]\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss: 0.935161\n",
      "==>>> epoch: 0, batch index: 200, train loss: 0.304810\n",
      "==>>> epoch: 0, batch index: 300, train loss: 0.184477\n",
      "==>>> epoch: 0, batch index: 400, train loss: 0.141505\n",
      "==>>> epoch: 0, batch index: 500, train loss: 0.129110\n",
      "==>>> epoch: 0, batch index: 600, train loss: 0.104364\n",
      "==>>> epoch: 0, batch index: 100, test loss: 0.081243, acc: 0.974\n",
      "==>>> epoch: 1, batch index: 100, train loss: 0.098751\n",
      "==>>> epoch: 1, batch index: 200, train loss: 0.079283\n",
      "==>>> epoch: 1, batch index: 300, train loss: 0.075309\n",
      "==>>> epoch: 1, batch index: 400, train loss: 0.081972\n",
      "==>>> epoch: 1, batch index: 500, train loss: 0.072649\n",
      "==>>> epoch: 1, batch index: 600, train loss: 0.072463\n",
      "==>>> epoch: 1, batch index: 100, test loss: 0.053357, acc: 0.982\n",
      "==>>> epoch: 2, batch index: 100, train loss: 0.067677\n",
      "==>>> epoch: 2, batch index: 200, train loss: 0.074438\n",
      "==>>> epoch: 2, batch index: 300, train loss: 0.038355\n",
      "==>>> epoch: 2, batch index: 400, train loss: 0.046647\n",
      "==>>> epoch: 2, batch index: 500, train loss: 0.051589\n",
      "==>>> epoch: 2, batch index: 600, train loss: 0.065239\n",
      "==>>> epoch: 2, batch index: 100, test loss: 0.032851, acc: 0.988\n",
      "==>>> epoch: 3, batch index: 100, train loss: 0.044081\n",
      "==>>> epoch: 3, batch index: 200, train loss: 0.058481\n",
      "==>>> epoch: 3, batch index: 300, train loss: 0.042794\n",
      "==>>> epoch: 3, batch index: 400, train loss: 0.033949\n",
      "==>>> epoch: 3, batch index: 500, train loss: 0.030502\n",
      "==>>> epoch: 3, batch index: 600, train loss: 0.066075\n",
      "==>>> epoch: 3, batch index: 100, test loss: 0.048827, acc: 0.983\n",
      "==>>> epoch: 4, batch index: 100, train loss: 0.041299\n",
      "==>>> epoch: 4, batch index: 200, train loss: 0.038574\n",
      "==>>> epoch: 4, batch index: 300, train loss: 0.034048\n",
      "==>>> epoch: 4, batch index: 400, train loss: 0.038654\n",
      "==>>> epoch: 4, batch index: 500, train loss: 0.031063\n",
      "==>>> epoch: 4, batch index: 600, train loss: 0.035427\n",
      "==>>> epoch: 4, batch index: 100, test loss: 0.026743, acc: 0.989\n",
      "==>>> epoch: 5, batch index: 100, train loss: 0.023436\n",
      "==>>> epoch: 5, batch index: 200, train loss: 0.030034\n",
      "==>>> epoch: 5, batch index: 300, train loss: 0.020036\n",
      "==>>> epoch: 5, batch index: 400, train loss: 0.025898\n",
      "==>>> epoch: 5, batch index: 500, train loss: 0.026484\n",
      "==>>> epoch: 5, batch index: 600, train loss: 0.023125\n",
      "==>>> epoch: 5, batch index: 100, test loss: 0.025377, acc: 0.991\n",
      "==>>> epoch: 6, batch index: 100, train loss: 0.017362\n",
      "==>>> epoch: 6, batch index: 200, train loss: 0.030326\n",
      "==>>> epoch: 6, batch index: 300, train loss: 0.016240\n",
      "==>>> epoch: 6, batch index: 400, train loss: 0.020746\n",
      "==>>> epoch: 6, batch index: 500, train loss: 0.022896\n",
      "==>>> epoch: 6, batch index: 600, train loss: 0.028782\n",
      "==>>> epoch: 6, batch index: 100, test loss: 0.019623, acc: 0.992\n",
      "==>>> epoch: 7, batch index: 100, train loss: 0.018504\n",
      "==>>> epoch: 7, batch index: 200, train loss: 0.017458\n",
      "==>>> epoch: 7, batch index: 300, train loss: 0.014768\n",
      "==>>> epoch: 7, batch index: 400, train loss: 0.022925\n",
      "==>>> epoch: 7, batch index: 500, train loss: 0.028725\n",
      "==>>> epoch: 7, batch index: 600, train loss: 0.015846\n",
      "==>>> epoch: 7, batch index: 100, test loss: 0.019858, acc: 0.992\n",
      "==>>> epoch: 8, batch index: 100, train loss: 0.015732\n",
      "==>>> epoch: 8, batch index: 200, train loss: 0.016380\n",
      "==>>> epoch: 8, batch index: 300, train loss: 0.010102\n",
      "==>>> epoch: 8, batch index: 400, train loss: 0.011137\n",
      "==>>> epoch: 8, batch index: 500, train loss: 0.008480\n",
      "==>>> epoch: 8, batch index: 600, train loss: 0.013787\n",
      "==>>> epoch: 8, batch index: 100, test loss: 0.019157, acc: 0.992\n",
      "==>>> epoch: 9, batch index: 100, train loss: 0.007726\n",
      "==>>> epoch: 9, batch index: 200, train loss: 0.012950\n",
      "==>>> epoch: 9, batch index: 300, train loss: 0.014019\n",
      "==>>> epoch: 9, batch index: 400, train loss: 0.013684\n",
      "==>>> epoch: 9, batch index: 500, train loss: 0.018629\n",
      "==>>> epoch: 9, batch index: 600, train loss: 0.019810\n",
      "==>>> epoch: 9, batch index: 100, test loss: 0.024935, acc: 0.991\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# from __future__ import division\n",
    "for epoch in range(iters):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print ('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "                epoch, batch_idx+1, ave_loss))\n",
    "    # testing\n",
    "    correct_cnt, ave_loss = 0.0, 0.0\n",
    "    total_cnt = 0.0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "#         print(type(total_cnt))\n",
    "#         print(correct_cnt.shape)\n",
    "        # smooth average\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "#         correct_cnt = correct_cnt.to(dtype=torch.float)\n",
    "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "            acc = float(correct_cnt * 1.0) / float(total_cnt)\n",
    "            print ('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx+1, ave_loss, acc))\n",
    "\n",
    "torch.save(model.state_dict(), model.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "\n",
    "# create foolbox model\n",
    "fmodel = foolbox.models.PyTorchModel(model.eval(), bounds=(0, 1), num_classes=10)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=10000,\n",
    "                shuffle=False)\n",
    "\n",
    "for batch_idx, (x, target) in enumerate(test_loader2):\n",
    "    x, target = x, target\n",
    "\n",
    "np_x = x.numpy()\n",
    "\n",
    "target_np = target.numpy()\n",
    "\n",
    "attack = foolbox.attacks.FGSM(fmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17231455 -0.50687265 13.178063    0.06572521 -1.2752354  -4.5391955\n",
      " -6.497519    2.0420296   3.7798073  -4.7475743 ]\n",
      "normal classification: 2\n",
      "[ 1.0051271  -4.6436906   4.3408804  -0.24396259  1.0494922  -4.1640477\n",
      " -5.9663115   0.5157756   5.8895545   2.8715756 ]\n",
      "adv classification 8\n"
     ]
    }
   ],
   "source": [
    "image_idx = 400\n",
    "\n",
    "print(fmodel.predictions(np_x[image_idx]))\n",
    "\n",
    "print(\"normal classification:\", np.argmax(fmodel.predictions(np_x[image_idx])))\n",
    "\n",
    "adv = attack(np_x[image_idx], int(target[image_idx]),epsilons=[0.14])\n",
    "\n",
    "print(fmodel.predictions(adv))\n",
    "print(\"adv classification\", np.argmax(fmodel.predictions(adv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Legitimate')\n",
    "plt.imshow(np.reshape(np_x[image_idx],[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Adverserial')\n",
    "plt.imshow(np.reshape(adv,[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Difference')\n",
    "diff = np.reshape(np_x[image_idx],[28,28]) - np.reshape(adv,[28,28])\n",
    "plt.imshow(diff/abs(diff).max() * 0.2 + 0.5, interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "# plt.show()\n",
    "plt.savefig('adv_diff.png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fmodel._model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_idx = []\n",
    "for idx in range(len(target_np)):\n",
    "    if(target_np[idx] == 0):\n",
    "        zero_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_x = np_x[zero_idx]\n",
    "\n",
    "features = fmodel._model.features\n",
    "classifer = fmodel._model.classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([980, 1, 28, 28])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=fmodel._model.features[1](torch.from_numpy(zero_x).cuda())\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research/rraju2/anaconda2/envs/torch3/lib/python3.5/site-packages/foolbox/attacks/base.py:148: UserWarning: GradientSignAttack did not find an adversarial, maybe the model or the criterion is not supported by this attack.\n",
      "  ' attack.'.format(self.name()))\n",
      "/research/rraju2/anaconda2/envs/torch3/lib/python3.5/site-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
      "  warnings.warn('Not running the attack because the original input'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661\n"
     ]
    }
   ],
   "source": [
    "# it takes a long time to run this cell \n",
    "adv_errors = 0\n",
    "for i in range(10000):\n",
    "    image = np_x[i]\n",
    "    label = target_np[i]\n",
    "#     print('normal class:', np.argmax(fmodel.predictions(image)), label)\n",
    "    adv = attack(image, int(label))\n",
    "    pred = np.argmax(fmodel.predictions(image))\n",
    "    if adv is not None:\n",
    "        adv_pred = np.argmax(fmodel.predictions(adv))\n",
    "        if pred != adv_pred:\n",
    "            adv_errors = adv_errors + 1\n",
    "\n",
    "print(adv_errors/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
