{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.utils import data\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.processed_folder, self.test_file))\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_gzip(gzip_path, remove_finished=False):\n",
    "        print('Extracting {}'.format(gzip_path))\n",
    "        with open(gzip_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                gzip.GzipFile(gzip_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "        if remove_finished:\n",
    "            os.unlink(gzip_path)\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        makedir_exist_ok(self.raw_folder)\n",
    "        makedir_exist_ok(self.processed_folder)\n",
    "\n",
    "        # download files\n",
    "        for url in self.urls:\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.raw_folder, filename)\n",
    "            download_url(url, root=self.raw_folder, filename=filename, md5=None)\n",
    "            self.extract_gzip(gzip_path=file_path, remove_finished=True)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "# trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "# from torchvision.datasets.utils import download_url, makedir_exist_ok\n",
    "\n",
    "import errno\n",
    "def makedir_exist_ok(dirpath):\n",
    "    \"\"\"\n",
    "    Python2 support for os.makedirs(.., exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(dirpath)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def download_url(url, root, filename, md5):\n",
    "    from six.moves import urllib\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    makedir_exist_ok(root)\n",
    "\n",
    "    # downloads file\n",
    "    if os.path.isfile(fpath) and check_integrity(fpath, md5):\n",
    "        print('Using downloaded and verified file: ' + fpath)\n",
    "    else:\n",
    "        try:\n",
    "            print('Downloading ' + url + ' to ' + fpath)\n",
    "            urllib.request.urlretrieve(\n",
    "                url, fpath,\n",
    "                reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "            )\n",
    "        except OSError:\n",
    "            if url[:5] == 'https':\n",
    "                url = url.replace('https:', 'http:')\n",
    "                print('Failed download. Trying https -> http instead.'\n",
    "                      ' Downloading ' + url + ' to ' + fpath)\n",
    "                urllib.request.urlretrieve(\n",
    "                    url, fpath,\n",
    "                    reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n",
    "                )\n",
    "def gen_bar_updater(pbar):\n",
    "    def bar_update(count, block_size, total_size):\n",
    "        if pbar.total is None and total_size:\n",
    "            pbar.total = total_size\n",
    "        progress_bytes = count * block_size\n",
    "        pbar.update(progress_bytes - pbar.n)\n",
    "\n",
    "    return bar_update\n",
    "def check_integrity(fpath, md5=None):\n",
    "    if md5 is None:\n",
    "        return True\n",
    "    if not os.path.isfile(fpath):\n",
    "        return False\n",
    "    md5o = hashlib.md5()\n",
    "    with open(fpath, 'rb') as f:\n",
    "        # read in 1MB chunks\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
    "            md5o.update(chunk)\n",
    "    md5c = md5o.hexdigest()\n",
    "    if md5c != md5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n",
    "    \n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "train_set = MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "### script file\n",
    "\n",
    "# Parameters for training on GPU \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# params = {'batch_size': 64,\n",
    "#          'shuffle': True,\n",
    "#          'num_workers': 6}\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                dataset=train_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print ('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print ('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Linear(128*4*4, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.classifer(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "    # returns activation values for a specific input x\n",
    "#     def eval_act_features(self, x):\n",
    "#         activations = []\n",
    "#         for idx in range(len(self.features)):\n",
    "#             features[idx]\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss: 1.107905\n",
      "==>>> epoch: 0, batch index: 200, train loss: 0.297107\n",
      "==>>> epoch: 0, batch index: 300, train loss: 0.163386\n",
      "==>>> epoch: 0, batch index: 400, train loss: 0.157907\n",
      "==>>> epoch: 0, batch index: 500, train loss: 0.150595\n",
      "==>>> epoch: 0, batch index: 600, train loss: 0.089652\n",
      "==>>> epoch: 0, batch index: 100, test loss: 0.083989, acc: 0.972\n",
      "==>>> epoch: 1, batch index: 100, train loss: 0.084506\n",
      "==>>> epoch: 1, batch index: 200, train loss: 0.099376\n",
      "==>>> epoch: 1, batch index: 300, train loss: 0.087921\n",
      "==>>> epoch: 1, batch index: 400, train loss: 0.076241\n",
      "==>>> epoch: 1, batch index: 500, train loss: 0.057023\n",
      "==>>> epoch: 1, batch index: 600, train loss: 0.065243\n",
      "==>>> epoch: 1, batch index: 100, test loss: 0.061061, acc: 0.978\n",
      "==>>> epoch: 2, batch index: 100, train loss: 0.053431\n",
      "==>>> epoch: 2, batch index: 200, train loss: 0.054164\n",
      "==>>> epoch: 2, batch index: 300, train loss: 0.059244\n",
      "==>>> epoch: 2, batch index: 400, train loss: 0.056633\n",
      "==>>> epoch: 2, batch index: 500, train loss: 0.060250\n",
      "==>>> epoch: 2, batch index: 600, train loss: 0.064225\n",
      "==>>> epoch: 2, batch index: 100, test loss: 0.036288, acc: 0.985\n",
      "==>>> epoch: 3, batch index: 100, train loss: 0.040934\n",
      "==>>> epoch: 3, batch index: 200, train loss: 0.035281\n",
      "==>>> epoch: 3, batch index: 300, train loss: 0.035264\n",
      "==>>> epoch: 3, batch index: 400, train loss: 0.042405\n",
      "==>>> epoch: 3, batch index: 500, train loss: 0.024564\n",
      "==>>> epoch: 3, batch index: 600, train loss: 0.030126\n",
      "==>>> epoch: 3, batch index: 100, test loss: 0.024923, acc: 0.989\n",
      "==>>> epoch: 4, batch index: 100, train loss: 0.037251\n",
      "==>>> epoch: 4, batch index: 200, train loss: 0.042836\n",
      "==>>> epoch: 4, batch index: 300, train loss: 0.024435\n",
      "==>>> epoch: 4, batch index: 400, train loss: 0.024700\n",
      "==>>> epoch: 4, batch index: 500, train loss: 0.032323\n",
      "==>>> epoch: 4, batch index: 600, train loss: 0.021886\n",
      "==>>> epoch: 4, batch index: 100, test loss: 0.023166, acc: 0.990\n",
      "==>>> epoch: 5, batch index: 100, train loss: 0.026978\n",
      "==>>> epoch: 5, batch index: 200, train loss: 0.020473\n",
      "==>>> epoch: 5, batch index: 300, train loss: 0.025896\n",
      "==>>> epoch: 5, batch index: 400, train loss: 0.022811\n",
      "==>>> epoch: 5, batch index: 500, train loss: 0.027238\n",
      "==>>> epoch: 5, batch index: 600, train loss: 0.018300\n",
      "==>>> epoch: 5, batch index: 100, test loss: 0.018199, acc: 0.991\n",
      "==>>> epoch: 6, batch index: 100, train loss: 0.026089\n",
      "==>>> epoch: 6, batch index: 200, train loss: 0.013044\n",
      "==>>> epoch: 6, batch index: 300, train loss: 0.027323\n",
      "==>>> epoch: 6, batch index: 400, train loss: 0.016571\n",
      "==>>> epoch: 6, batch index: 500, train loss: 0.012212\n",
      "==>>> epoch: 6, batch index: 600, train loss: 0.016768\n",
      "==>>> epoch: 6, batch index: 100, test loss: 0.020016, acc: 0.991\n",
      "==>>> epoch: 7, batch index: 100, train loss: 0.015486\n",
      "==>>> epoch: 7, batch index: 200, train loss: 0.025299\n",
      "==>>> epoch: 7, batch index: 300, train loss: 0.021725\n",
      "==>>> epoch: 7, batch index: 400, train loss: 0.021736\n",
      "==>>> epoch: 7, batch index: 500, train loss: 0.019160\n",
      "==>>> epoch: 7, batch index: 600, train loss: 0.019555\n",
      "==>>> epoch: 7, batch index: 100, test loss: 0.021610, acc: 0.990\n",
      "==>>> epoch: 8, batch index: 100, train loss: 0.013997\n",
      "==>>> epoch: 8, batch index: 200, train loss: 0.016039\n",
      "==>>> epoch: 8, batch index: 300, train loss: 0.018454\n",
      "==>>> epoch: 8, batch index: 400, train loss: 0.018876\n",
      "==>>> epoch: 8, batch index: 500, train loss: 0.019398\n",
      "==>>> epoch: 8, batch index: 600, train loss: 0.027502\n",
      "==>>> epoch: 8, batch index: 100, test loss: 0.026027, acc: 0.987\n",
      "==>>> epoch: 9, batch index: 100, train loss: 0.012829\n",
      "==>>> epoch: 9, batch index: 200, train loss: 0.008010\n",
      "==>>> epoch: 9, batch index: 300, train loss: 0.019408\n",
      "==>>> epoch: 9, batch index: 400, train loss: 0.014436\n",
      "==>>> epoch: 9, batch index: 500, train loss: 0.014888\n",
      "==>>> epoch: 9, batch index: 600, train loss: 0.008897\n",
      "==>>> epoch: 9, batch index: 100, test loss: 0.021732, acc: 0.991\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# from __future__ import division\n",
    "for epoch in range(iters):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print ('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "                epoch, batch_idx+1, ave_loss))\n",
    "    # testing\n",
    "    correct_cnt, ave_loss = 0.0, 0.0\n",
    "    total_cnt = 0.0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "#         print(type(total_cnt))\n",
    "#         print(correct_cnt.shape)\n",
    "        # smooth average\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "#         correct_cnt = correct_cnt.to(dtype=torch.float)\n",
    "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "            acc = float(correct_cnt * 1.0) / float(total_cnt)\n",
    "            print ('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx+1, ave_loss, acc))\n",
    "\n",
    "torch.save(model.state_dict(), model.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "\n",
    "# create foolbox model\n",
    "fmodel = foolbox.models.PyTorchModel(model.eval(), bounds=(0, 1), num_classes=10)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=10000,\n",
    "                shuffle=False)\n",
    "\n",
    "for batch_idx, (x, target) in enumerate(test_loader2):\n",
    "    x, target = x, target\n",
    "\n",
    "np_x = x.numpy()\n",
    "\n",
    "target_np = target.numpy()\n",
    "\n",
    "attack = foolbox.attacks.FGSM(fmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5344129  -2.3880734  13.048282    0.98991877 -0.7775176  -4.196883\n",
      " -6.4003415  -0.7726093   1.3642799  -3.156856  ]\n",
      "normal classification: 2\n",
      "[ 4.935063  -4.8018956  4.762754   2.0161464 -1.9008274 -2.7528062\n",
      " -5.818899  -1.5559013  3.3923798  2.2492034]\n",
      "adv classification 0\n"
     ]
    }
   ],
   "source": [
    "image_idx = 400\n",
    "\n",
    "print(fmodel.predictions(np_x[image_idx]))\n",
    "\n",
    "print(\"normal classification:\", np.argmax(fmodel.predictions(np_x[image_idx])))\n",
    "\n",
    "adv = attack(np_x[image_idx], int(target[image_idx]),epsilons=[epsilon])\n",
    "\n",
    "print(fmodel.predictions(adv))\n",
    "print(\"adv classification\", np.argmax(fmodel.predictions(adv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Legitimate')\n",
    "plt.imshow(np.reshape(np_x[image_idx],[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Adverserial')\n",
    "plt.imshow(np.reshape(adv,[28,28]), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Difference')\n",
    "diff = np.reshape(np_x[image_idx],[28,28]) - np.reshape(adv,[28,28])\n",
    "plt.imshow(diff/abs(diff).max() * 0.2 + 0.5, interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "# plt.show()\n",
    "plt.savefig('adv_diff.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.17\n",
    "trial_eps = np.linspace(0.15, 0.5)\n",
    "# it takes a long time to run this cell \n",
    "adv_errors = 0\n",
    "classification_rates = []\n",
    "\n",
    "for ep in trial_eps:\n",
    "    \n",
    "    for i in range(1000):\n",
    "        image = np_x[i]\n",
    "        label = target_np[i]\n",
    "    #     print('normal class:', np.argmax(fmodel.predictions(image)), label)\n",
    "        adv = attack(image, int(label))\n",
    "        pred = np.argmax(fmodel.predictions(image))\n",
    "        if adv is not None:\n",
    "            adv_pred = np.argmax(fmodel.predictions(adv))\n",
    "            if pred != adv_pred:\n",
    "                adv_errors = adv_errors + 1\n",
    "    acc = (1-(adv_errors/1000))\n",
    "    classification_rates.append(acc)\n",
    "    print(\"For ep: {:.2f}, classification rate: {:.3f}\".format(\n",
    "                ep, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classification_ra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
